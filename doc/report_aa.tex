\documentclass[]{IEEEtran}

\title{Sparse Matrix Transposition for GPUs}
\author{Massimiliano Incudini - VR433300\\Michele Penzo - VR439232}

\usepackage{graphicx}
\usepackage[export]{adjustbox}
\usepackage[italian]{babel}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% todo
% spiegare come abbiamo fatto i test (che valori), e mostrare tabella con varie dimensioni delle matrici e nnz
% kernel scan, scantrans, sort, index to pointers, pointer index
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}
\maketitle

\begin{abstract}
	L'obiettivo principale di questo progetto è stato quello di implementare alcune metodologie proposte per effettuare \textit{Sparse Matrix Transposition} su \textit{Gpu}.
	Sono stati analizzati alcuni algoritmi, descritti in sezione~\ref{metodologie}, partendo dall'algoritmo seriale, passando a cuSPARSE per finire con l'implementazione degli algoritmi descritti in~\cite{parallelTrans}.
	Infine vengono esposti i risultati e tratte le conclusioni.
\end{abstract}


\section{Introduzione}
\label{introduzione}
	Sempre più applicazioni computazionali in ambito scientifico necessitano di algoritmi che compiano operazioni che si possano applicare su matrici sparse. Si parla di semplici operazioni di algebra lineare, di moltiplicazione o di calcolo della trasposta come nel nostro caso.\newline
	Il problema analizzato, quello della trasposizione di matrici, si presta bene al calcolo parallelo per aumentarne l'efficienza. Verranno quindi mostrate le basi per la rappresentazione ed analizzati alcuni algoritmi per il calcolo su \textit{Gpu}.


\section{Rappresentazione delle matrici}
\label{rappresentazione}
	Viene detta matrice sparsa una matrice in cui i valori sono quasi tutti uguali a zero. Per rappresentare in modo efficacie, senza troppi sprechi di memoria, sono stati introdotte varie forme di rappresentazione matriciale. La struttura dati classica utilizza una quantità di memoria minima di $ m $ x $ n $ elementi.\newline
	Sono state quindi utilizzate delle rappresentazioni che permettono il salvataggio di dati utilizzando quantitativi di memoria inferiori.
	
	\subsection{Csr}
	\label{csr}
	Il \textit{compressed sparse row} è una rappresentazione di una matrice $ M $ basata su tre array monodimensionali, che rispettivamente contengono:
	\begin{enumerate}
		\item \textit{V}: i valori \textit{nnz},
		\item \textit{COL\_INDEX}: gli indici delle colonne dove si trovano gli elementi \textit{nnz},
		\item \textit{ROW\_INDEX}: rappresenta l'indice in $ V $ dove la riga comincia
	\end{enumerate}
	I primi due array sono di dimensione \textit{nnz}, mentre il terzo array è al massimo di dimensione $ M $.
	
	\subsection{Csc}
	\label{csc}
 	Questa metodologia per la rappresentazione è simile alla sopra citata \textit{Csr}, solo che i valori vengono letti prima per colonna. Di conseguenza, un indice di riga viene memorizzato per ogni valore e i puntatori di colonna vengono memorizzati.
 	
\section{Struttura dell'implementazione} 
% come è stato strutturato il pkg?


\section{Metodologie analizzate}
\label{metodologie}
	In questa sezione vengono spiegate ed evidenziate le differenze tra le varie metodologie analizzate. 
		
	\subsection{Trasposta seriale}
	La prima metodologia descritta è quella seriale. Sempre a partire dalla rappresentazione in formato \textit{csr} della matrice iniziale l'algoritmo crea un array di elementi, dove per ogni colonna della matrice analizzata conta quanti elementi \textbf{nnz} ci sono. Possiamo definire questo array come un istogramma delle frequenze degli elementi delle colonne. Viene quindi applicato un algoritmo seriale di \textit{prefix\_sum} su questo array, che conterrà ora i valori corretti di \textbf{cscColPtr}. Infine gli indici di riga e i valori nel nuovo formato \textit{csc} vengono sistemati.\newline
	Questa implementazione servirà come base sulla quale verranno eseguiti i controlli degli algoritmi successivamente implementati.
	
	\subsection{Nvidia cuSPARSE}
	Questo toolkit è implementato all'interno nelle librerie NVIDIA CUDA runtime. Le routine delle librerie vengono utilizzate per le operazioni tra vettori e matrici che sono rappresentate tramite diversi formati. Inoltre mette a disposione operazioni che permettono la conversione attraverso diverse rappresentazioni di matrici, ed inoltre la compressione in formato \textit{csr} che è una delle più usate quando si vuole rappresentare matrici sparse in modo efficiente.\newline	
	Il codice è stato sviluppato basandosi su due versioni di cuSPARSE a causa delle Gpu utilizzate. In fase di compilazione viene quindi controllata la versione usata: $ 9 $ o $ 10 $.\newline
	Nel caso in cui la versione usata sia la $ 10 $ vengono svolti alcuni ulteriori passi, viene effettuata l'allocazione dello spazio necessario e del buffer per il calcolo della trasposta. Per quanto riguarda la versione $ 9 $ invece questi passi non sono necessari.\newline
	Infine viene chiamata la procedura che effettua il calcolo della trasposta. \newline
	Le procedure chiamate sono diverse in base alla funzione. Nel primo caso viene chiamata \textbf{cusparseScsr2csc}, mentre nel secondo caso \textbf{cusparseCsr2cscEx2}. Quest'ultima richiede come parametro anche l'algoritmo che viene utilizzato all'interno della procedura.\newline
	Dopo essere state eseguite entrambe ritornano i valori ottenuti tramite un'altro formato, \textit{csc}, che ne esprime la rappresentazione tramite valori come csrColIdx, cscVal, cscColPtr, cscRowIdx. Infine viene controllata la correttezza e i tempi rispetto alle altre implementazioni.

	\subsection{ScanTrans}
	
	
	\subsection{MergeTrans}
	

\section{Esperimenti}
\label{esperimenti}
	% dataset? matrici come sono state implementate?
	
\section{Risultati}
\label{risultati}


\section{Conclusioni}
\label{conclusioni}



\bibliographystyle{IEEEtran}
\bibliography{biblio}

%\appendix
%Se non avete abbastanza spazio, potete inserire le figure delle EFSM in una  pagina extra, appendice. Un esempio di come potete fare solo le Figure~\ref{fig:grande}, \ref{fig:piccola1}, \ref{fig:piccola2}.

\end{document}