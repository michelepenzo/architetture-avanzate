\documentclass[]{IEEEtran}

\usepackage[italian]{babel}
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{float}
\usepackage[export]{adjustbox}
\usepackage{dirtree}
\usepackage{hyperref}
\usepackage{tikz}

% tabella dei risultati
\usepackage{array}
\usepackage{siunitx}
\usepackage{booktabs}

\newcommand{\ScanTrans}{\textrm{ScanTrans} }
\newcommand{\MergeTrans}{\textrm{MergeTrans} }
\newcommand{\BlockSize}{\textrm{BLOCK\_SIZE} }
\newcommand{\SplitterDistance}{\textrm{SP\_DIST} }
\newcommand{\cuSPARSE}{\textrm{cuSPARSE} }


\graphicspath{{figures/}} 	

\newcommand*\circled[1]{\tikz[baseline=(char.base)]{\node[shape=circle,draw,inner sep=2pt] (char) {#1};}}

\title{Sparse Matrix Transposition for GPUs}
\author{Massimiliano Incudini - VR433300\\Michele Penzo - VR439232}

\begin{document}
\maketitle

\begin{abstract}
	L'obiettivo principale di questo progetto è stato quello di implementare alcune metodologie proposte per effettuare \textit{Sparse Matrix Transposition} su \textit{Gpu}.
	Sono stati analizzati alcuni algoritmi, descritti in sezione~\ref{metodologie}, partendo dall'algoritmo seriale, passando a cuSPARSE per finire con l'implementazione degli algoritmi descritti in~\cite{parallelTrans}.
	Infine vengono esposti i risultati e tratte le conclusioni.
\end{abstract}


\section{Introduzione}
\label{introduzione}
	% problema e motivazioni
	Sempre più applicazioni computazionali in ambito scientifico necessitano di algoritmi che compiano operazioni applicabili su matrici sparse. Si parla di semplici operazioni di algebra lineare, di moltiplicazione o di calcolo della trasposta come in questo caso.\newline
	Il problema analizzato, quello della trasposizione di matrici, si presta bene al calcolo parallelo per l'esecuzione in maniera più efficiente e veloce. Verranno quindi mostrate le basi per la rappresentazione, i problemi riscontrati durante lo sviluppo e analizzati alcuni algoritmi per il calcolo su \textit{Gpu}.\newline


\section{Rappresentazione delle matrici}
\label{rappresentazione}
	Una matrice sparsa non è altro che una matrice i cui valori sono per la maggior parte uguali a zero. La matrice in formato classico necessita di una quantità di memoria minima di $ m $x$ n $ elementi, ma essendo l'obiettivo quello di lavorare su matrici sparse non è stato necessario e utile memorizzare la matrice in formato denso.\newline
	Per rappresentare in modo efficace le matrici sparse senza troppo utilizzo di memoria sono state quindi introdotte ed utilizzate delle forme di rappresentazione matriciale che permettono il salvataggio di dati utilizzando quantitativi di memoria inferiori.\newline
	Di seguito vengono spiegate le due metodologie da noi utilizzate.
	
	\subsection{Formato Csr}
	\label{csr}
	Il \textit{compressed sparse row} è una rappresentazione di una matrice $ M $ basata su tre array monodimensionali, che rispettivamente contengono:
	\begin{enumerate}
		\item \textit{V}: i valori non zero (\textit{nnz}),
		\item \textit{COL\_INDEX}: gli indici delle colonne dove si trovano gli elementi \textit{nnz},
		\item \textit{ROW\_INDEX}: ha un elemento per ogni riga della matrice e rappresenta l'indice in $ V $ dove comincia la riga data.
	\end{enumerate}
	I primi due array sono di dimensione \textit{nnz}, mentre il terzo array è al massimo di dimensione $ m $.
	
	\subsection{Formato Csc}
	\label{csc}
 	Questa metodologia per la rappresentazione è simile alla precedente citata \textit{Csr}, a differenza che i valori vengono letti prima per colonna. Di conseguenza, un indice di riga viene memorizzato per ogni valore e lo stesso viene fatto per i puntatori di colonna .
 	
	\subsection{Da Csr a Csc}
	\label{csr-to-csc}
 	Per il problema della trasposta di matrice è stato quindi utile introdurre entrambe le rappresentazioni. Infatti, ogni algoritmo  descritto in sezione~\ref{metodologie}, necessita di sei array per effettuare il calcolo della trasposta e dare l'output nella tipologia corretta. Abbiamo quindi:
 	\begin{itemize}
 		\item in input il formato \textit{Csr}: csrRowPtr, csrColIdx, csrVal;
 		\item in output il formato \textit{Csc}: cscColPtr, cscRowIdx, cscVal.	
 	\end{itemize}
 	In base a come vengono create le matrici, se in modo casuale oppure se lette da file, vengono effettutate delle operazioni preliminari descritte dalla procedure in sezione~\ref{procedure} che portano ad ottenere gli array in input e in output nel formato corretto per effettuarne il controllo di correttezza.\newline
	
	% TODO disegnino fatto meglio
	\begin{figure}[H]
		\includegraphics[scale=0.25]{csr-to-csc.jpg}
		\caption{Esempio di trasformazione da formato Csr a Csc.}
	\end{figure}

	
\section{Struttura dell'implementazione} 
\label{struttura}
	L'implementazione è stata sviluppata utilizzando come supporto il tool \textit{Git}. È stata creata una repository, descritta nella sezione successiva, per poter controllare in modo efficiente lo svilupparsi del progetto. \newline
	
	\noindent Link repo: 	\href{https://github.com/michelepenzo/architetture-avanzate}{github.com/michelepenzo/architetture-avanzate}\newline
	
	\subsection{Struttura delle directory}
	La struttura delle directory è rispecchiata nel seguente schema:
	\dirtree{%
		.1 root.
			.2 doc.
				.3 {report\_aa.$ * $}.				
			.2 code.
				.3 {matrices}.
					.4 {$ *$.mtx }.
				.3 {include}.
					.4 {matrix.hh}.
					.4 {merge\_step.hh}.
					.4 {procedures.hh}.
					.4 {transposers.hh}.
					.4 {Timer.$ * $}.
					.4 {utilities.hh}.
				.3 {src}.
					.4 {all cuda procedures..}.
					.4 {transposer.cu}.
					.4 {main.cu}.
				.3 {test}.	
					.4 {test\_main.cu}.
				.3 Makefile.			
				.3 {timing\_analysis.csv}.			
			.2 README.md.
	}
	\mbox{}

	Il file \texttt{matrix.hh} è composto da due classi con i relativi campi e metodi che si occupa della:
	\begin{enumerate}
		\item costruzione della matrice sparsa in formato Csr: \textit{class~SparseMatrix},
		\item costruzione della matrice densa: \textit{class FullMatrix}.
	\end{enumerate}
	Il file \texttt{procedures.hh} contiene tutte le procedure descritte in sezione~\ref{procedure} ed è diviso in due \texttt{namespace}. Essi riferiscono all'implementazione effettuta, ovvero \textit{cuda} o \textit{reference}(seriale).\newline
	È presente inoltre il file \texttt{transposers.hh} che funge da ``wrapper'' per le quattro implementazioni descritte nella prossima sezione.\newline
	Un'altro file è il \texttt{merge\_step.hh} che contiene tutte le implementazioni del \textit{segmented merge descritto} in \ref{seg-merge}.\newline
	Infine abbiamo il timer e un file che contiene tutte le funzioni utilizzate utili per debug, stampa, allocazione e deallocazione, generazione dei valori random, controllo errori e altro.\newline
	
	All'interno della direcotry \textit{src} abbiamo tutte le implementazioni delle procedure cuda utilizzate nel progetto, oltre che al file \texttt{transposers.cu} che contiene le implementazioni descritte in~\ref{metodologie}.\newline
	Infine è presente il \texttt{main.cu}, che si occupa di eseguire tutte le metodologie implementate.\newline

	È presente inoltre un'ultima directory con relativo file che si occupa della fase di test delle singole componenti.
	
	\subsection{Test delle componenti}	
	Per le singole componenti(scan, sort, index to pointers ...) è stato implementato un'altro eseguibile. Lanciando il comando \textit{make test} viene eseguito l'applicativo che effettuta il test prima per piccole istanze e poi per grandi istanze. Cosi facendo tutte le componenti vengono testate con diversi valori.\newline
	La singola componente del programma viene quindi eseguita sia con la sua implementazione seriale, sia con quella in parallelo. Tramite questa modalità stato più semplice testare le singole componenti e successivamente, dopo aver effettuato dei test complessi ed averli superati a parte, è risultato più semplice unire il tutto per ottenere l'implementazione finale.
	
	\subsection{Applicativo finale}
	\label{applicativo-finale}
	% più matrici testate assieme
	Tramite il comando \textit{make run} viene eseguito l'applicativo finale. Questo esegue per un numero di iterazioni le metodologie implementate. All'interno del tag \texttt{run} nel \textit{Makefile} viene eseguito varie volte l'eseguibile, ogni volta con valori diversi.\newline
	Il file eseguibile può essere eseguito passando:
	\begin{itemize}
		\item un valore (\textit{file.mtx}): esegue le metodolgie su una matrice sparsa caricata da file,
		\item tre valori (\textit{m n nnz}): prende i tre valori classici per la creazione della matrice e genera casualmente la matrice sparsa delle dimensioni richieste,
		\item nessun valore: matrice generate casualmente con valori fissi.
	\end{itemize}
	Alla fine le tempistiche vengono concatenate all'interno del file \textit{timing\_analysis.csv} per effettuarne una migliore lettura.


\section{Metodologie analizzate}
\label{metodologie}
	In questa sezione vengono spiegate ed evidenziate le differenze tra le varie metodologie analizzate. 
		
	\subsection{Trasposta seriale}
%	La prima metodologia descritta è quella seriale. Sempre a partire dalla rappresentazione in formato \textit{csr} della matrice iniziale l'algoritmo crea un array di elementi, dove per ogni colonna della matrice analizzata conta quanti elementi \textbf{nnz} ci sono. Possiamo definire questo array come un istogramma delle frequenze degli elementi delle colonne. 
	La prima metodologia descritta è quella seriale. Sempre a partire dalla rappresentazione in formato \textit{csr} della matrice iniziale l'algoritmo ottiene i puntatori alle colonne (formato csc) a partire dagli indici di colonna (formato csr). Viene quindi applicato un algoritmo seriale di \textit{prefix\_sum} su questo array, per ottenere i valori corretti di \textbf{cscColPtr}. Infine gli indici di riga e i valori nel nuovo formato \textit{csc} vengono sistemati.\newline
	Questa implementazione servirà come base sulla quale verranno eseguiti i controlli degli algoritmi successivamente implementati.
	
	\subsection{Nvidia cuSPARSE}
	Questo toolkit è implementato all'interno nelle librerie NVIDIA CUDA runtime. Le routine delle librerie vengono utilizzate per operazioni tra vettori e matrici che sono rappresentate tramite diversi formati. Inoltre mette a disposione operazioni che permettono la conversione attraverso diverse rappresentazioni di matrici. Supporta inoltre la compressione in formato \textit{csr} che è una delle più usate quando si vuole rappresentare matrici sparse in modo efficiente.\newline	
	Il codice è stato sviluppato partendo dalla guida \cite{cusparse} ed è diviso in due versioni di cuSPARSE a causa delle Gpu utilizzate. In fase di compilazione viene quindi controllata la versione usata: $ 9 $ o $ 10 $.\newline
	Nel caso in cui la versione usata sia la $ 10 $ vengono svolti alcuni ulteriori passi, come l'allocazione dello spazio necessario per l'esecuzione di cuSparse oltre all'allocazione del buffer per il calcolo della trasposta. Per quanto riguarda la versione $ 9 $ invece questi passi non sono necessari.\newline
	Infine viene chiamata la procedura che effettua il calcolo della trasposta. Nel caso in cui la versione di cuSPARSE sia la $ 10 $ viene richiesto come ulteriore parametro l'algoritmo da utilizzare.\newline
	Dopo essere state eseguite entrambe ritornano i valori ottenuti in formato \textit{csc}.

	\subsection{ScanTrans}
	L'algoritmo considerato prevede di effettuare la trasposta di matrici basandosi sul concetto di scan. Partendo sempre dal presupposto di avere in input una matrice in formato \textit{Csr}, vengono costruiti due array ausiliari:
	\begin{itemize}
		\item inter: array bidimensionale di dimensione $ (nthreads+1) * n $,
		\item intra: array monodimensionale di dimensione massima $ nnz $.
	\end{itemize}
	Ogni riga in \textit{inter} contiene il numero di indici della colonna presi dalla thread i-esima. Mentre ogni elemento in \textit{intra} viene utilizzato per salvare l'offeset relativo alla colonna corrispondente all'elemento nnz preso dalla thread. Dopo aver ottenuto gli istogrammi, viene applicato un \textit{vertical scan} su inter, e una \textit{prefix sum} solamente sull'ultima riga di inter. Infine l'algoritmo calcola l'offset assoluto relativo ad ogni elemento nnz e ritorna il tutto in formato \textit{csc}.\newline
	Tutte le procedure utilizzate in \textit{Scan Trans} si trovano in sezione \ref{procedure}, e vengono eseguite nel seguente ordine:
	\begin{enumerate}
		\item pointers to index: \ref{pnt-to-idx},
		\item index to pointers: \ref{idx-to-pnt},
		\item scan: \ref{scan},
		\item reorder elements: \ref{reoder-elem}.
	\end{enumerate}
	
	\begin{figure}[H]
		\includegraphics[scale=0.6]{scantrans.png}
		\caption{Scan Trans, esempio utilizzato in \cite{parallelTrans}.}
		\label{scantrans}
	\end{figure}
	
	\subsection{MergeTrans}
	L'algoritmo considerato prevede due passi importanti: \textit{sort} e \textit{merge}.
	Inizialmente sono stati creati gli indici di riga a partire dai puntatori delle colonne e su questi ultimi è stato fatto un sort su piccole porzioni di array, mantenendo quindi i vari blocchi disordinati tra di loro ma con gli elementi ordinati. Successivamente è stato utilizzato il merge ricorsivo partendo dai blocchi più piccoli e unendoli in blocchi sempre più grandi. Per funzionare questo processo necessita dell'utilizzo di due buffer di memoria che contengono gli elementi appena ordinati. Infine dai puntatori delle colonne vengono estraxtti gli indici e viene fatta la scan che ritorna il risultato in formato \textit{csc}. \newline
	Anche in questo caso le procedure utilizzate si trovano in sezione \ref{procedure}, e sono ordinatamente eseguite come segue:
	\begin{enumerate}
		\item pointers to index: \ref{pnt-to-idx},
		\item segmented sort: \ref{seg-sort},
		\item segmented merge: \ref{seg-merge},
		\item index to pointers: \ref{idx-to-pnt},
		\item scan: \ref{scan}.
	\end{enumerate}
	
	\begin{figure}[H]
		\includegraphics[scale=0.6]{mergetrans.png}
		\caption{Merge Trans, esempio utilizzato in \cite{parallelTrans}.}
		\label{mergetrans}
	\end{figure}
	
% Inserimento sezione delle procedure
\input{procedure}

\input{risultati}
	
\section{Conclusioni}
\label{conclusioni}
	% tirare le somme di cosa abbiamo ottenuto
	% cosa migliorare?
	% come possiamo continuare il progetto se avessimo avuto più tempo?
		% algo merge con merge buffer che è gia implementato
		% testare l'efficienza delle componenti rispetto alla implementazione nvidia
		% idx to pntrs (soffre race condition) --> un thread ha un blocco
		

\bibliographystyle{IEEEtran}
\bibliography{biblio}


%\appendix
%Se non avete abbastanza spazio, potete inserire le figure delle EFSM in una  pagina extra, appendice. Un esempio di come potete fare solo le Figure~\ref{fig:grande}, \ref{fig:piccola1}, \ref{fig:piccola2}.

\end{document}