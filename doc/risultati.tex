

\section{Risultati sperimentali}

Confrontiamo ora le performance delle varie implementazioni che seguono:
\begin{itemize}
    \item seriale;
    \item parallela \emph{scan trans};
    \item parallela \emph{merge trans};
    \item \cuSPARSE{} (entrambi gli algoritmi).
\end{itemize}

Le istanze su cui vengono eseguiti i vari algoritmi sono in parte generate in modo casuale (a partire dalle specifiche della matrice sparsa), in parte recuperate dal dataset "University  of Florida sparse  matrix collection`` \cite{dataset}. Tale dataset è stato usato per valutare le performance degli algoritmi in \cite{parallelTrans}.

La macchina sul quale vengono eseguiti i vari algoritmi è equipaggiata con una scheda NVidia GeForce GTX 780 con Cuda Runtime 10.2.

I risultati sono visibili in Tabella~\ref{results} (tempistiche) e in Tabella~\ref{results_speedup} (speedup).

Analizzando i risultati notiamo che per istanze di dimensioni notevoli l'implementazione \ScanTrans{} raggiunge speedup fino a $\times 2.5$ rispetto all'algoritmo seriale, mentre le due implementazioni fornite da \cuSPARSE{} raggiungono $\times 6.0$ e $\times 9.8$ di speedup. 

L'implementazione \MergeTrans{} risulta sempre meno efficiente della versione seriale dell'algoritmo. I possibili problemi relativi a questa implementazione sono discussi in Sezione~\ref{conclusioni}.





\section{Considerazioni finali}\label{conclusioni}

Contrariamente a quanto asserito in \cite{parallelTrans}, nel nostro caso \ScanTrans{} si comporta meglio di \MergeTrans{}. Proponiamo alcune idee per migliorare il risultato:
\begin{itemize}
	\item utilizzare un algoritmo più efficiente per realizzare il merge quale il \textit{Merge Path} (\cite{mergepath});
	\item la procedure da noi descritte potrennero essere sostituite con quelle fornite nella libreria \textit{modern gpu} presente su Github; inoltre seguendo la descrizione delle implementazioni presenti in \cite{moderngpu} ci avrebbe aiutato nella fase di ingegnerizzazione.
	\item la procedura \emph{istogramma} (\var{index\_to\_pointers}) può essere migliorata nel seguente modo: attualmente una griglia di un unico thread calcola l'istogramma parziale sulla sua porzione di vettore; si potrebbero introdurre tante thread ognuna che legge l'intera porzione di blocco ma si occupa di processare gli elementi appartenenti ad una sola (o ad un piccolo insieme) di valori. Questo permetterebbe anche di caricare gli elementi in shared memory, eventualmente una porzione di blocco per volta.
\end{itemize}

