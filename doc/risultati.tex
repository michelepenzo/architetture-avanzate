\input{tabella_risultati}

\section{Risultati sperimentali}

Confrontiamo ora le performance delle varie implementazioni che seguono:
\begin{itemize}
    \item seriale;
    \item parallela \emph{scan trans};
    \item parallela \emph{merge trans};
    \item \cuSPARSE (2).
\end{itemize}

Le istanze su cui vengono eseguiti i vari algoritmi sono in parte generate in modo casuale (a partire dalle specifiche della matrice sparsa), in parte recuperate dal dataset "University  of Florida sparse  matrix collection`` \cite{dataset}. Tale dataset è stato usato per valutare le performance degli algoritmi in \cite{parallelTrans}.

La macchina sul quale vengono eseguiti i vari algoritmi è equipaggiata con una scheda NVidia GeForce GTX 780 con Cuda Runtime 10.2.

I risultati sono visibili in Tabella~\ref{results}. 

\section{Considerazioni finali}\label{conclusioni}
Possiamo notare come le implementazioni citate in \cite{parallelTrans} e da noi sviluppate non siano all'altezza delle versioni di \cuSPARSE.

Contrariamente a quanto asserito in \cite{parallelTrans}, nel nostro caso \textit{Scan Trans} si comporta meglio di \textit{Merge Trans}. Questo potrebbe essere dovuto all'implementazione da noi usata nel merge spiegato in sezione \ref{merge} e dalle diverse ottimizzazioni utilizzate nell'implementazione del paper della quale non ne siamo a conoscenza.

Abbiamo inoltre notato come \ScanTrans ottenga risultati migliori se eseguito su matrici ``random'' dove i valori, a differenza delle matrici in formato \texttt{.mtx}, sono interi e non decimali.

Come possibili future implementazioni per migliorare l'efficienza del progetto abbiamo pensato come il package \textit{modern gpu} prenste su Github ci possa tornare utile. Esso mette a disposione implementazioni di alcuni componenti a noi utili per l'obiettivo finale. A partire da queste implementazioni avremmo potuto confrontare le componenti da noi sviluppate con quelle presenti per capire dove migliorare. 



