

\section{Risultati sperimentali}

Confrontiamo ora le performance delle varie implementazioni che seguono:
\begin{itemize}
    \item seriale;
    \item parallela \emph{scan trans};
    \item parallela \emph{merge trans};
    \item \cuSPARSE   (entrambi gli algoritmi).
\end{itemize}

Le istanze su cui vengono eseguiti i vari algoritmi sono in parte generate in modo casuale (a partire dalle specifiche della matrice sparsa), in parte recuperate dal dataset "University  of Florida sparse  matrix collection`` \cite{dataset}. Tale dataset è stato usato per valutare le performance degli algoritmi in \cite{parallelTrans}.

La macchina sul quale vengono eseguiti i vari algoritmi è equipaggiata con una scheda NVidia GeForce GTX 780 con Cuda Runtime 10.2.

I risultati sono visibili in Tabella~\ref{results} (tempistiche) e in Tabella~\ref{results_speedup} (speedup).

Analizzando i risultati notiamo che per istanze di dimensioni notevoli l'implementazione \ScanTrans{} raggiunge speedup fino a $\times 2.5$ rispetto all'algoritmo seriale, mentre le due implementazioni fornite da \cuSPARSE{} raggiungono $\times 6.0$ e $\times 9.8$ di speedup. 

L'implementazione \MergeTrans{} risulta sempre meno efficiente della versione seriale dell'algoritmo. I possibili problemi relativi a questa implementazione sono discussi in Sezione~\ref{conclusioni}.





\section{Considerazioni finali}\label{conclusioni}

Contrariamente a quanto asserito in \cite{parallelTrans}, nel nostro caso \ScanTrans{} si comporta meglio di \MergeTrans{}. Proponiamo alcune idee per migliorare il risultato:
\begin{itemize}
	\item utilizzare un algoritmo più efficiente per realizzare il merge: \textit{Merge Path} citato in \cite{merge},
	\item provare a sostituire da noi descritte con quelle fornite nella libreria \textit{modern gpu} presente su Github,
	\item inoltre seguendo la descrizione delle implementazioni presenti in \cite{moderngpu} ci avrebbe aiutato nella fase di ingegnerizzazione.
\end{itemize}

